{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XrqkKgP9wZZA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVGEN3n6xIlH"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4vh65uSHrOw2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2TL_8Z6YrRoQ"
   },
   "outputs": [],
   "source": [
    "# Number of Residual Layers\n",
    "# res_layer_num = 0\n",
    "# Number of Residual blocks in Residual Layer i\n",
    "res_block_nums = [2, 2, 4, 1]\n",
    "# Number of channels in Residual Layer i\n",
    "channel_nums = [48, 96, 192, 384]\n",
    "# Conv. kernel size in Residual Layer i\n",
    "# conv_kernel_sizes = []\n",
    "# Skip connection kernel size in Residual Layer i\n",
    "# skip_kernel_sizes = []\n",
    "# Average pool kernel size\n",
    "avg_pool_kernel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NNzBIQv8aISO"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, channel_nums[0], num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, channel_nums[1], num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, channel_nums[2], num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, channel_nums[3], num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(channel_nums[3], num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, avg_pool_kernel_size)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def project1_model_reference():\n",
    "    return ResNet(BasicBlock, [3, 4, 5, 3])\n",
    "\n",
    "#returns our ResNet architecture\n",
    "def project1_model():\n",
    "    return ResNet(BasicBlock, res_block_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LMCK96UcaSDX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 48, 32, 32]          27,648\n",
      "       BatchNorm2d-4           [-1, 48, 32, 32]              96\n",
      "            Conv2d-5           [-1, 48, 32, 32]          20,736\n",
      "       BatchNorm2d-6           [-1, 48, 32, 32]              96\n",
      "            Conv2d-7           [-1, 48, 32, 32]           3,072\n",
      "       BatchNorm2d-8           [-1, 48, 32, 32]              96\n",
      "        BasicBlock-9           [-1, 48, 32, 32]               0\n",
      "           Conv2d-10           [-1, 48, 32, 32]          20,736\n",
      "      BatchNorm2d-11           [-1, 48, 32, 32]              96\n",
      "           Conv2d-12           [-1, 48, 32, 32]          20,736\n",
      "      BatchNorm2d-13           [-1, 48, 32, 32]              96\n",
      "       BasicBlock-14           [-1, 48, 32, 32]               0\n",
      "           Conv2d-15           [-1, 96, 16, 16]          41,472\n",
      "      BatchNorm2d-16           [-1, 96, 16, 16]             192\n",
      "           Conv2d-17           [-1, 96, 16, 16]          82,944\n",
      "      BatchNorm2d-18           [-1, 96, 16, 16]             192\n",
      "           Conv2d-19           [-1, 96, 16, 16]           4,608\n",
      "      BatchNorm2d-20           [-1, 96, 16, 16]             192\n",
      "       BasicBlock-21           [-1, 96, 16, 16]               0\n",
      "           Conv2d-22           [-1, 96, 16, 16]          82,944\n",
      "      BatchNorm2d-23           [-1, 96, 16, 16]             192\n",
      "           Conv2d-24           [-1, 96, 16, 16]          82,944\n",
      "      BatchNorm2d-25           [-1, 96, 16, 16]             192\n",
      "       BasicBlock-26           [-1, 96, 16, 16]               0\n",
      "           Conv2d-27            [-1, 192, 8, 8]         165,888\n",
      "      BatchNorm2d-28            [-1, 192, 8, 8]             384\n",
      "           Conv2d-29            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-30            [-1, 192, 8, 8]             384\n",
      "           Conv2d-31            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-32            [-1, 192, 8, 8]             384\n",
      "       BasicBlock-33            [-1, 192, 8, 8]               0\n",
      "           Conv2d-34            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-35            [-1, 192, 8, 8]             384\n",
      "           Conv2d-36            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-37            [-1, 192, 8, 8]             384\n",
      "       BasicBlock-38            [-1, 192, 8, 8]               0\n",
      "           Conv2d-39            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-40            [-1, 192, 8, 8]             384\n",
      "           Conv2d-41            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-42            [-1, 192, 8, 8]             384\n",
      "       BasicBlock-43            [-1, 192, 8, 8]               0\n",
      "           Conv2d-44            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-45            [-1, 192, 8, 8]             384\n",
      "           Conv2d-46            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-47            [-1, 192, 8, 8]             384\n",
      "       BasicBlock-48            [-1, 192, 8, 8]               0\n",
      "           Conv2d-49            [-1, 384, 4, 4]         663,552\n",
      "      BatchNorm2d-50            [-1, 384, 4, 4]             768\n",
      "           Conv2d-51            [-1, 384, 4, 4]       1,327,104\n",
      "      BatchNorm2d-52            [-1, 384, 4, 4]             768\n",
      "           Conv2d-53            [-1, 384, 4, 4]          73,728\n",
      "      BatchNorm2d-54            [-1, 384, 4, 4]             768\n",
      "       BasicBlock-55            [-1, 384, 4, 4]               0\n",
      "           Linear-56                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 4,971,882\n",
      "Trainable params: 4,971,882\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.14\n",
      "Params size (MB): 18.97\n",
      "Estimated Total Size (MB): 29.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet = project1_model().cuda();\n",
    "summary(resnet,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zNAWCJy_3jC7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor(0.1000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from imgaug.augmenters.contrast import GammaContrast\n",
    "from imgaug.augmenters.blur import GaussianBlur\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "#run on gpu or cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#EPOCH = 50   \n",
    "BATCH_SIZE = 256      \n",
    "LR = 0.1        #learning rate\n",
    "\n",
    "#data transform\n",
    "\n",
    "#training transform with imgaug lib:\n",
    "transform_train_img =  transforms.Compose([\n",
    "                                           transforms.RandomCrop(32, padding=4),  #do zero padding and then crop the image randomly into 32x32 picture\n",
    "                                           transforms.RandomHorizontalFlip(),  #50% flip the image horizontally \n",
    "                                           np.asarray,\n",
    "    iaa.Sequential([\n",
    "                    iaa.Sometimes(0.1,iaa.AdditiveGaussianNoise(scale=(0, 0.2*255))),#add gaussian noise\n",
    "                    iaa.Sometimes(0.1, iaa.GammaContrast((0.5, 2.0))),# 2 contrast enhancing techniques\n",
    "                    iaa.Sometimes(0.1, iaa.LinearContrast((0.5, 2.0), per_channel=0.5)),\n",
    "    ]).augment_image,\n",
    "    np.copy,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) #normalization\n",
    "])\n",
    "\n",
    "#testing transform\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dataset loading\n",
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_img) \n",
    "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainDataLoader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "testDataLoader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "dataloaders = {'train': trainDataLoader, 'val': testDataLoader}\n",
    "#resnet =  resnet().to(device)\n",
    "resnet.eval()\n",
    "corrects = 0\n",
    "\n",
    "\n",
    "for batch_idx, (inputs,labels) in enumerate(testDataLoader, 1):\n",
    "  with torch.set_grad_enabled(False):\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    outputs = resnet(inputs)\n",
    "    _, preds = torch.max(outputs,1)    \n",
    "  corrects += torch.sum(preds == labels.data)\n",
    "print(corrects.float() / len(testDataLoader.dataset))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "#SGD optimizer\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)#*0.5 every 15 steps\n",
    "\n",
    "\n",
    "cur_lr_list = []\n",
    "save_loss = {'train':[], 'val':[]}\n",
    "save_acc = {'train':[], 'val':[]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llaoOMEo3kia"
   },
   "outputs": [],
   "source": [
    "accIdeal = 0.9445#save model with preferred result \n",
    "\n",
    "f = 1\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            resnet.train()  # Set model to training mode\n",
    "        else:\n",
    "            resnet.eval()   # Set model to evaluate mode\n",
    "\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloaders[phase], 1):\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Time to carry out the forward training poss\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = resnet(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "\n",
    "            # We want variables to hold the loss/acc statistics\n",
    "            current_loss += loss.item() * inputs.size(0)\n",
    "            current_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if phase == 'train':\n",
    "                    scheduler.step()  #update learning rate\n",
    "                    cur_lr=optimizer.param_groups[-1]['lr']\n",
    "                    cur_lr_list.append(cur_lr)\n",
    "\n",
    "        # saving variable for plottin\n",
    "        save_loss[phase] += [current_loss / len(dataloaders[phase].dataset)]\n",
    "        save_acc[phase] += [current_corrects.float() / len(dataloaders[phase].dataset)]\n",
    "\n",
    "        # pretty print\n",
    "        print(f\"Epoch:{epoch} -- Phase:{phase} -- Loss:{save_loss[phase][-1]:.2f} -- Acc:{save_acc[phase][-1]*100:.2f}\")\n",
    "        if f != 1:\n",
    "                  if save_acc['val'][-1] >= accIdeal:\n",
    "                    accIdeal = save_acc['val'][-1]\n",
    "                    torch.save(resnet.state_dict(),'./drive/My Drive/para_' + str(accIdeal) + '.pt')\n",
    "        f = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSnVPG_w8zFv"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(),'./drive/My Drive/para_324.pt')#save the final model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V1MVVeGSc89"
   },
   "outputs": [],
   "source": [
    "#Accuracy curves\n",
    "for i in range(len(save_acc['train'])):\n",
    "    save_acc['train'][i]=save_acc['train'][i].cpu().numpy()\n",
    "    save_acc['val'][i]=save_acc['val'][i].cpu().numpy()\n",
    "    #save_acc['train'][i]=save_acc['train'][i]\n",
    "    #save_acc['val'][i]=save_acc['val'][i]\n",
    "plt.plot(save_acc['train'])\n",
    "plt.plot(save_acc['val'])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig('./drive/My Drive/acc.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEWdecuW3vHI"
   },
   "outputs": [],
   "source": [
    "#learning rate curve\n",
    "x_list = list(range(len(cur_lr_list)))\n",
    "plt.plot(x_list, cur_lr_list)\n",
    "plt.title(\"Learning rate\")\n",
    "plt.savefig('./drive/My Drive/LR.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rAiCj1PyX_t"
   },
   "outputs": [],
   "source": [
    "#loss curves\n",
    "for i in range(len(save_loss['train'])):\n",
    "    save_loss['train'][i]=save_loss['train'][i]\n",
    "    save_loss['val'][i]=save_loss['val'][i]\n",
    "plt.plot(save_loss['train'])\n",
    "plt.plot(save_loss['val'])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig('./drive/My Drive/loss.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJdjYDVtqVBu"
   },
   "source": [
    "End of the script.\n",
    "References included in the project report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKGUrnX7eN4_"
   },
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinalTrainScript.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
