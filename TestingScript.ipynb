{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cq0DiPv75qi3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-HtM3hNp56R3"
      },
      "outputs": [],
      "source": [
        "# Number of Residual blocks in Residual Layer i\n",
        "res_block_nums = [2, 2, 4, 1]\n",
        "# Number of channels in Residual Layer i\n",
        "channel_nums = [48, 96, 192, 384]\n",
        "# Average pool kernel size\n",
        "avg_pool_kernel_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7LvIJDKb5_gV"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, channel_nums[0], num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, channel_nums[1], num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, channel_nums[2], num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, channel_nums[3], num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(channel_nums[3], num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, avg_pool_kernel_size)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def project1_model_reference():\n",
        "    return ResNet(BasicBlock, [3, 4, 5, 3])\n",
        "\n",
        "def project1_model():\n",
        "    return ResNet(BasicBlock, res_block_nums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CiuHE-BX6dpt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet = project1_model().cuda()\n",
        "\n",
        "resnet.load_state_dict(torch.load('./project1_model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MQmDxSnPxJ1F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight \t torch.Size([64, 3, 3, 3])\n",
            "bn1.weight \t torch.Size([64])\n",
            "bn1.bias \t torch.Size([64])\n",
            "bn1.running_mean \t torch.Size([64])\n",
            "bn1.running_var \t torch.Size([64])\n",
            "bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.conv1.weight \t torch.Size([48, 64, 3, 3])\n",
            "layer1.0.bn1.weight \t torch.Size([48])\n",
            "layer1.0.bn1.bias \t torch.Size([48])\n",
            "layer1.0.bn1.running_mean \t torch.Size([48])\n",
            "layer1.0.bn1.running_var \t torch.Size([48])\n",
            "layer1.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.conv2.weight \t torch.Size([48, 48, 3, 3])\n",
            "layer1.0.bn2.weight \t torch.Size([48])\n",
            "layer1.0.bn2.bias \t torch.Size([48])\n",
            "layer1.0.bn2.running_mean \t torch.Size([48])\n",
            "layer1.0.bn2.running_var \t torch.Size([48])\n",
            "layer1.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.shortcut.0.weight \t torch.Size([48, 64, 1, 1])\n",
            "layer1.0.shortcut.1.weight \t torch.Size([48])\n",
            "layer1.0.shortcut.1.bias \t torch.Size([48])\n",
            "layer1.0.shortcut.1.running_mean \t torch.Size([48])\n",
            "layer1.0.shortcut.1.running_var \t torch.Size([48])\n",
            "layer1.0.shortcut.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.1.conv1.weight \t torch.Size([48, 48, 3, 3])\n",
            "layer1.1.bn1.weight \t torch.Size([48])\n",
            "layer1.1.bn1.bias \t torch.Size([48])\n",
            "layer1.1.bn1.running_mean \t torch.Size([48])\n",
            "layer1.1.bn1.running_var \t torch.Size([48])\n",
            "layer1.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.1.conv2.weight \t torch.Size([48, 48, 3, 3])\n",
            "layer1.1.bn2.weight \t torch.Size([48])\n",
            "layer1.1.bn2.bias \t torch.Size([48])\n",
            "layer1.1.bn2.running_mean \t torch.Size([48])\n",
            "layer1.1.bn2.running_var \t torch.Size([48])\n",
            "layer1.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.conv1.weight \t torch.Size([96, 48, 3, 3])\n",
            "layer2.0.bn1.weight \t torch.Size([96])\n",
            "layer2.0.bn1.bias \t torch.Size([96])\n",
            "layer2.0.bn1.running_mean \t torch.Size([96])\n",
            "layer2.0.bn1.running_var \t torch.Size([96])\n",
            "layer2.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.conv2.weight \t torch.Size([96, 96, 3, 3])\n",
            "layer2.0.bn2.weight \t torch.Size([96])\n",
            "layer2.0.bn2.bias \t torch.Size([96])\n",
            "layer2.0.bn2.running_mean \t torch.Size([96])\n",
            "layer2.0.bn2.running_var \t torch.Size([96])\n",
            "layer2.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.shortcut.0.weight \t torch.Size([96, 48, 1, 1])\n",
            "layer2.0.shortcut.1.weight \t torch.Size([96])\n",
            "layer2.0.shortcut.1.bias \t torch.Size([96])\n",
            "layer2.0.shortcut.1.running_mean \t torch.Size([96])\n",
            "layer2.0.shortcut.1.running_var \t torch.Size([96])\n",
            "layer2.0.shortcut.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.1.conv1.weight \t torch.Size([96, 96, 3, 3])\n",
            "layer2.1.bn1.weight \t torch.Size([96])\n",
            "layer2.1.bn1.bias \t torch.Size([96])\n",
            "layer2.1.bn1.running_mean \t torch.Size([96])\n",
            "layer2.1.bn1.running_var \t torch.Size([96])\n",
            "layer2.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer2.1.conv2.weight \t torch.Size([96, 96, 3, 3])\n",
            "layer2.1.bn2.weight \t torch.Size([96])\n",
            "layer2.1.bn2.bias \t torch.Size([96])\n",
            "layer2.1.bn2.running_mean \t torch.Size([96])\n",
            "layer2.1.bn2.running_var \t torch.Size([96])\n",
            "layer2.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.conv1.weight \t torch.Size([192, 96, 3, 3])\n",
            "layer3.0.bn1.weight \t torch.Size([192])\n",
            "layer3.0.bn1.bias \t torch.Size([192])\n",
            "layer3.0.bn1.running_mean \t torch.Size([192])\n",
            "layer3.0.bn1.running_var \t torch.Size([192])\n",
            "layer3.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.conv2.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.0.bn2.weight \t torch.Size([192])\n",
            "layer3.0.bn2.bias \t torch.Size([192])\n",
            "layer3.0.bn2.running_mean \t torch.Size([192])\n",
            "layer3.0.bn2.running_var \t torch.Size([192])\n",
            "layer3.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.shortcut.0.weight \t torch.Size([192, 96, 1, 1])\n",
            "layer3.0.shortcut.1.weight \t torch.Size([192])\n",
            "layer3.0.shortcut.1.bias \t torch.Size([192])\n",
            "layer3.0.shortcut.1.running_mean \t torch.Size([192])\n",
            "layer3.0.shortcut.1.running_var \t torch.Size([192])\n",
            "layer3.0.shortcut.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.1.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.1.bn1.weight \t torch.Size([192])\n",
            "layer3.1.bn1.bias \t torch.Size([192])\n",
            "layer3.1.bn1.running_mean \t torch.Size([192])\n",
            "layer3.1.bn1.running_var \t torch.Size([192])\n",
            "layer3.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.1.conv2.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.1.bn2.weight \t torch.Size([192])\n",
            "layer3.1.bn2.bias \t torch.Size([192])\n",
            "layer3.1.bn2.running_mean \t torch.Size([192])\n",
            "layer3.1.bn2.running_var \t torch.Size([192])\n",
            "layer3.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.2.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.2.bn1.weight \t torch.Size([192])\n",
            "layer3.2.bn1.bias \t torch.Size([192])\n",
            "layer3.2.bn1.running_mean \t torch.Size([192])\n",
            "layer3.2.bn1.running_var \t torch.Size([192])\n",
            "layer3.2.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.2.conv2.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.2.bn2.weight \t torch.Size([192])\n",
            "layer3.2.bn2.bias \t torch.Size([192])\n",
            "layer3.2.bn2.running_mean \t torch.Size([192])\n",
            "layer3.2.bn2.running_var \t torch.Size([192])\n",
            "layer3.2.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.3.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.3.bn1.weight \t torch.Size([192])\n",
            "layer3.3.bn1.bias \t torch.Size([192])\n",
            "layer3.3.bn1.running_mean \t torch.Size([192])\n",
            "layer3.3.bn1.running_var \t torch.Size([192])\n",
            "layer3.3.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.3.conv2.weight \t torch.Size([192, 192, 3, 3])\n",
            "layer3.3.bn2.weight \t torch.Size([192])\n",
            "layer3.3.bn2.bias \t torch.Size([192])\n",
            "layer3.3.bn2.running_mean \t torch.Size([192])\n",
            "layer3.3.bn2.running_var \t torch.Size([192])\n",
            "layer3.3.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.conv1.weight \t torch.Size([384, 192, 3, 3])\n",
            "layer4.0.bn1.weight \t torch.Size([384])\n",
            "layer4.0.bn1.bias \t torch.Size([384])\n",
            "layer4.0.bn1.running_mean \t torch.Size([384])\n",
            "layer4.0.bn1.running_var \t torch.Size([384])\n",
            "layer4.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.conv2.weight \t torch.Size([384, 384, 3, 3])\n",
            "layer4.0.bn2.weight \t torch.Size([384])\n",
            "layer4.0.bn2.bias \t torch.Size([384])\n",
            "layer4.0.bn2.running_mean \t torch.Size([384])\n",
            "layer4.0.bn2.running_var \t torch.Size([384])\n",
            "layer4.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.shortcut.0.weight \t torch.Size([384, 192, 1, 1])\n",
            "layer4.0.shortcut.1.weight \t torch.Size([384])\n",
            "layer4.0.shortcut.1.bias \t torch.Size([384])\n",
            "layer4.0.shortcut.1.running_mean \t torch.Size([384])\n",
            "layer4.0.shortcut.1.running_var \t torch.Size([384])\n",
            "layer4.0.shortcut.1.num_batches_tracked \t torch.Size([])\n",
            "linear.weight \t torch.Size([10, 384])\n",
            "linear.bias \t torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for param_tensor in resnet.state_dict():\n",
        "    print(param_tensor, \"\\t\", resnet.state_dict()[param_tensor].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9w5LHpuCltT"
      },
      "source": [
        "Just Test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2fuCQ1ud6B_y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "tensor(0.9444, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#*** PERFORM NORMAILIZATION BEFORE TESTING\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testDataLoader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
        "#resnet =  resnet().to(device)\n",
        "resnet.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "corrects = 0\n",
        "for batch_idx, (inputs,labels) in enumerate(testDataLoader, 1):\n",
        "  with torch.set_grad_enabled(False):\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    outputs = resnet(inputs)\n",
        "    _, preds = torch.max(outputs,1)    \n",
        "  corrects += torch.sum(preds == labels.data)\n",
        "print(corrects.float() / len(testDataLoader.dataset))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TestingScript.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
