{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestingScript.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq0DiPv75qi3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from imgaug import augmenters as iaa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "id": "kFEKjv5EABYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Residual Layers\n",
        "# res_layer_num = 0\n",
        "# Number of Residual blocks in Residual Layer i\n",
        "res_block_nums = [2, 2, 4, 1]\n",
        "# Number of channels in Residual Layer i\n",
        "channel_nums = [48, 96, 192, 384]\n",
        "# Conv. kernel size in Residual Layer i\n",
        "# conv_kernel_sizes = []\n",
        "# Skip connection kernel size in Residual Layer i\n",
        "# skip_kernel_sizes = []\n",
        "# Average pool kernel size\n",
        "avg_pool_kernel_size = 4"
      ],
      "metadata": {
        "id": "-HtM3hNp56R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, channel_nums[0], num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, channel_nums[1], num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, channel_nums[2], num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, channel_nums[3], num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(channel_nums[3], num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, avg_pool_kernel_size)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def project1_model_reference():\n",
        "    return ResNet(BasicBlock, [3, 4, 5, 3])\n",
        "\n",
        "def project1_model():\n",
        "    return ResNet(BasicBlock, res_block_nums)"
      ],
      "metadata": {
        "id": "7LvIJDKb5_gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = project1_model().cuda()\n",
        "\n",
        "resnet.load_state_dict(torch.load('model_state.pt'))"
      ],
      "metadata": {
        "id": "CiuHE-BX6dpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_tensor in resnet.state_dict():\n",
        "    print(param_tensor, \"\\t\", resnet.state_dict()[param_tensor].size())"
      ],
      "metadata": {
        "id": "MQmDxSnPxJ1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just Test:"
      ],
      "metadata": {
        "id": "d9w5LHpuCltT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#*** PERFORM NORMAILIZATION BEFORE TESTING\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testDataLoader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
        "#resnet =  resnet().to(device)\n",
        "resnet.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "corrects = 0\n",
        "for batch_idx, (inputs,labels) in enumerate(testDataLoader, 1):\n",
        "  with torch.set_grad_enabled(False):\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    outputs = resnet(inputs)\n",
        "    _, preds = torch.max(outputs,1)    \n",
        "  corrects += torch.sum(preds == labels.data)\n",
        "print(corrects.float() / len(testDataLoader.dataset))"
      ],
      "metadata": {
        "id": "2fuCQ1ud6B_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}